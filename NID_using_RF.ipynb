{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivam2Goyal/Advanced-Area-Computation-System/blob/main/NID_using_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings to keep the output clean\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the NSL-KDD dataset and define column names\n",
        "column_names = [\n",
        "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
        "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
        "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
        "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
        "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
        "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
        "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
        "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
        "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
        "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
        "    \"dst_host_srv_rerror_rate\", \"label\"\n",
        "]\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/content/KDDTrain+_20Percent.txt\", names=column_names)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Drop any missing values (if present)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert categorical columns into numerical values\n",
        "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
        "encoders = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    encoder = LabelEncoder()\n",
        "    df[col] = encoder.fit_transform(df[col])  # Convert text labels to numbers\n",
        "    encoders[col] = encoder  # Store encoders for potential inverse transformation\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Extract only numerical columns for standardization\n",
        "numeric_columns = X.select_dtypes(include=np.number).columns\n",
        "X_numeric = X[numeric_columns]\n",
        "\n",
        "# Apply standardization to scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_scaled_numeric = scaler.fit_transform(X_numeric)\n",
        "\n",
        "# Create a DataFrame with scaled numerical data\n",
        "X_scaled = pd.DataFrame(X_scaled_numeric, columns=numeric_columns, index=X.index)\n",
        "\n",
        "# Merge back the categorical (already encoded) columns\n",
        "X_scaled = pd.concat([X_scaled, X[categorical_features]], axis=1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "u8ivhkXZ7-7p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model using sklearn\n",
        "rf_sklearn = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42)\n",
        "rf_sklearn.fit(X_train, y_train)\n",
        "y_pred_sklearn = rf_sklearn.predict(X_test)\n",
        "\n",
        "# Print Sklearn Random Forest Accuracy\n",
        "print(f\"Sklearn Random Forest Accuracy: {accuracy_score(y_test, y_pred_sklearn)*100:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRD2r5Qk_Rcy",
        "outputId": "a4885f21-274e-4bda-9c56-c3f18aa2dba4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Random Forest Accuracy: 84.9230%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Random Forest from scratch (except using sklearn's DecisionTreeClassifier)\n",
        "class CustomRandomForest:\n",
        "    def __init__(self, n_trees=100, max_depth=None, min_samples_split=2, max_features=\"sqrt\"):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_features = max_features\n",
        "        self.trees = []\n",
        "\n",
        "    def bootstrap_sample(self, X, y):\n",
        "        \"\"\"Generates a bootstrapped dataset by randomly sampling with replacement.\"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        sample_indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return X.iloc[sample_indices], y.iloc[sample_indices]  # Select data using indices\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train multiple Decision Trees on different bootstrapped datasets.\"\"\"\n",
        "        self.trees = []\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        # Determine the number of features to consider for each tree\n",
        "        if self.max_features == \"sqrt\":\n",
        "            num_features = max(int(np.sqrt(n_features)), 10)  # Ensure a minimum of 10 features\n",
        "        elif self.max_features == \"log2\":\n",
        "            num_features = max(int(np.log2(n_features)), 10)\n",
        "        else:\n",
        "            num_features = n_features // 2  # Use half of the total features\n",
        "\n",
        "        for _ in range(self.n_trees):\n",
        "            X_sample, y_sample = self.bootstrap_sample(X, y)\n",
        "            selected_features = np.random.choice(n_features, num_features, replace=False)\n",
        "\n",
        "            # Train a Decision Tree using the selected subset of features\n",
        "            tree = DecisionTreeClassifier(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                criterion=\"gini\"\n",
        "            )\n",
        "            tree.fit(X_sample.iloc[:, selected_features], y_sample)\n",
        "            self.trees.append((tree, selected_features))  # Store both the tree and selected features\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict using majority voting across all Decision Trees.\"\"\"\n",
        "        predictions = np.zeros((X.shape[0], len(self.trees)))\n",
        "\n",
        "        for i, (tree, selected_features) in enumerate(self.trees):\n",
        "            predictions[:, i] = tree.predict(X.iloc[:, selected_features])\n",
        "\n",
        "        # Majority voting: select the most common prediction among all trees\n",
        "        final_predictions = np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=1, arr=predictions)\n",
        "        return final_predictions.astype(int)\n",
        "\n",
        "# Train the custom Random Forest model\n",
        "rf_custom = CustomRandomForest(n_trees=100, max_depth=None, min_samples_split=2)\n",
        "rf_custom.fit(X_train, y_train)\n",
        "y_pred_custom = rf_custom.predict(X_test)\n",
        "\n",
        "# Print Custom Random Forest Accuracy\n",
        "print(f\"Custom Random Forest Accuracy: {accuracy_score(y_test, y_pred_custom)*100:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzSWnVSq_kML",
        "outputId": "66578cd6-3875-4744-a98c-7b324eabbf71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Random Forest Accuracy: 76.5447%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}